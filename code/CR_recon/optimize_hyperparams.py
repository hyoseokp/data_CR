"""
Hyperparameter Optimizer: Train logë¥¼ ë¶„ì„í•˜ê³  ë” ë‚˜ì€ ì„¤ì •ì„ ì°¾ì•„ì¤Œ
ì‚¬ìš©: python optimize_hyperparams.py --log outputs/train_log.txt
"""
import argparse
import re
import yaml
from pathlib import Path
from typing import Dict, List, Tuple
import subprocess
import json


def parse_train_log(log_path: str) -> Dict:
    """Train logë¥¼ íŒŒì‹±í•´ì„œ ì„¤ì •ê³¼ ê²°ê³¼ ì¶”ì¶œ"""
    with open(log_path, 'r', encoding='utf-8') as f:
        content = f.read()

    result = {
        'model_name': None,
        'model_path': None,
        'model_params': {},
        'loss_name': None,
        'loss_path': None,
        'loss_params': {},
        'hyperparams': {},
        'best_val_loss': float('inf'),
        'final_val_loss': float('inf'),
        'epochs_trained': 0,
    }

    # Model ì •ë³´ ì¶”ì¶œ
    model_match = re.search(r'Model: (\w+)', content)
    if model_match:
        result['model_name'] = model_match.group(1)

    model_path_match = re.search(r'Model Path: ([\w/._-]+)', content)
    if model_path_match:
        result['model_path'] = model_path_match.group(1)

    # Model Parameters ì¶”ì¶œ
    model_params_section = re.search(
        r'Model Parameters:(.*?)(?=Loss Function|Hyperparameters)',
        content,
        re.DOTALL
    )
    if model_params_section:
        params_text = model_params_section.group(1)
        for line in params_text.split('\n'):
            match = re.search(r'-\s*(\w+):\s*(.*)', line)
            if match:
                param_name = match.group(1)
                param_value = match.group(2).strip()
                try:
                    result['model_params'][param_name] = yaml.safe_load(param_value)
                except:
                    result['model_params'][param_name] = param_value

    # Loss ì •ë³´ ì¶”ì¶œ
    loss_match = re.search(r'Loss Function: (\w+)', content)
    if loss_match:
        result['loss_name'] = loss_match.group(1)

    loss_path_match = re.search(r'Loss Path: ([\w/._-]+)', content)
    if loss_path_match:
        result['loss_path'] = loss_path_match.group(1)

    # Loss Parameters ì¶”ì¶œ
    loss_params_section = re.search(
        r'Loss Parameters:(.*?)(?=Hyperparameters)',
        content,
        re.DOTALL
    )
    if loss_params_section:
        params_text = loss_params_section.group(1)
        for line in params_text.split('\n'):
            match = re.search(r'-\s*(\w+):\s*(.*)', line)
            if match:
                param_name = match.group(1)
                param_value = match.group(2).strip()
                try:
                    result['loss_params'][param_name] = yaml.safe_load(param_value)
                except:
                    result['loss_params'][param_name] = param_value

    # Hyperparameters ì¶”ì¶œ
    hyper_section = re.search(
        r'Hyperparameters:(.*?)(?=Data Statistics)',
        content,
        re.DOTALL
    )
    if hyper_section:
        hyper_text = hyper_section.group(1)
        for line in hyper_text.split('\n'):
            match = re.search(r'-\s*([\w\s]+):\s*(.*)', line)
            if match:
                param_name = match.group(1).strip()
                param_value = match.group(2).strip()
                try:
                    result['hyperparams'][param_name] = yaml.safe_load(param_value)
                except:
                    result['hyperparams'][param_name] = param_value

    # Best val loss ì¶”ì¶œ
    best_loss_matches = re.findall(
        r'best_val=([\d.e+-]+)',
        content
    )
    if best_loss_matches:
        result['best_val_loss'] = float(best_loss_matches[-1])
        result['final_val_loss'] = float(best_loss_matches[-1])

    # Epochs trained ì¶”ì¶œ
    epoch_matches = re.findall(
        r'\[EPOCH\]\s+(\d+)/(\d+)',
        content
    )
    if epoch_matches:
        result['epochs_trained'] = int(epoch_matches[-1][0])

    return result


def generate_suggestions(log_data: Dict) -> List[Dict]:
    """ë¡œê·¸ ë¶„ì„ í›„ ê°œì„  ì œì•ˆ ìƒì„±"""
    suggestions = []

    print("\n" + "=" * 80)
    print("ANALYSIS & SUGGESTIONS")
    print("=" * 80)

    print(f"\nğŸ“Š Current Results:")
    print(f"  - Model: {log_data['model_name']}")
    print(f"  - Loss: {log_data['loss_name']}")
    print(f"  - Best Val Loss: {log_data['best_val_loss']:.6e}")
    print(f"  - Epochs Trained: {log_data['epochs_trained']}")

    # 1. Learning Rate ì¡°ì •
    current_lr = log_data['hyperparams'].get('Learning Rate', 0.001)
    if log_data['best_val_loss'] > 0.05:
        suggestions.append({
            'name': 'Increase Learning Rate',
            'description': f'Lossê°€ ë†’ìœ¼ë‹ˆ Learning Rateë¥¼ {current_lr} â†’ {current_lr * 2} ë¡œ ì¦ê°€',
            'config_changes': {'training': {'lr': current_lr * 2}},
            'reason': 'High loss indicates slow convergence'
        })
    elif log_data['best_val_loss'] < 0.01 and log_data['epochs_trained'] > 100:
        suggestions.append({
            'name': 'Decrease Learning Rate',
            'description': f'Lossê°€ ë§¤ìš° ë‚®ìœ¼ë‹ˆ ë¯¸ì„¸ ì¡°ì •: Learning Rate {current_lr} â†’ {current_lr * 0.5}',
            'config_changes': {'training': {'lr': current_lr * 0.5}},
            'reason': 'Fine-tuning for better convergence'
        })

    # 2. Model ë³€ê²½ ì œì•ˆ
    if log_data['model_name'] == 'cnn_xattn':
        suggestions.append({
            'name': 'Try CNN_GRU Model',
            'description': 'CNN_XAttn ëŒ€ì‹  CNN_GRU ëª¨ë¸ë¡œ ë¹„êµ (ê°„ë‹¨í•œ baseline)',
            'config_changes': {'model': {'name': 'cnn_gru'}},
            'reason': 'More lightweight, faster convergence'
        })
    elif log_data['model_name'] == 'cnn_gru':
        suggestions.append({
            'name': 'Try CNN_XAttn Model',
            'description': 'CNN_GRU ëŒ€ì‹  CNN_XAttn ëª¨ë¸ë¡œ ë¹„êµ (ë” ê°•ë ¥í•¨)',
            'config_changes': {'model': {'name': 'cnn_xattn'}},
            'reason': 'More expressive model with attention'
        })

    # 3. Loss Function ë³€ê²½ ì œì•ˆ
    if log_data['loss_name'] == 'mse_pearson':
        suggestions.append({
            'name': 'Try Weighted Smooth Loss',
            'description': 'MSE_Pearson ëŒ€ì‹  Weighted_Smooth Lossë¡œ ë¹„êµ (smoothness ì •ê·œí™”)',
            'config_changes': {'loss': {'name': 'weighted_smooth'}},
            'reason': 'Better for smooth spectral predictions'
        })
    elif log_data['loss_name'] == 'weighted_smooth':
        suggestions.append({
            'name': 'Try MSE_Pearson Loss',
            'description': 'Weighted_Smooth ëŒ€ì‹  MSE_Pearson Lossë¡œ ë¹„êµ',
            'config_changes': {'loss': {'name': 'mse_pearson'}},
            'reason': 'Scale/shift invariant, simpler'
        })

    # 4. Weight Decay ì¡°ì •
    wd = log_data['hyperparams'].get('Weight Decay', 0.005)
    if log_data['best_val_loss'] < 0.01:
        suggestions.append({
            'name': 'Increase Weight Decay',
            'description': f'Regularization ì¦ê°€: {wd} â†’ {wd * 2}',
            'config_changes': {'training': {'weight_decay': wd * 2}},
            'reason': 'Overfitting prevention'
        })

    # 5. Batch Size ì¡°ì •
    bs = log_data['hyperparams'].get('Batch Size', 64)
    if log_data['best_val_loss'] > 0.02:
        suggestions.append({
            'name': 'Increase Batch Size',
            'description': f'Batch Size ì¦ê°€: {bs} â†’ {bs * 2} (ì•ˆì •ì„± í–¥ìƒ)',
            'config_changes': {'data': {'batch_size': bs * 2}},
            'reason': 'Stable gradient estimates'
        })

    return suggestions


def create_test_configs(base_config_path: str, suggestions: List[Dict]) -> List[Tuple[str, Dict]]:
    """ê° ì œì•ˆì— ëŒ€í•´ í…ŒìŠ¤íŠ¸ config ìƒì„±"""
    with open(base_config_path, 'r') as f:
        base_config = yaml.safe_load(f)

    test_configs = []

    for i, suggestion in enumerate(suggestions):
        config = yaml.safe_load(yaml.dump(base_config))

        # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ epoch ì¤„ì„
        config['training']['epochs'] = min(5, config['training']['epochs'])

        # ì œì•ˆëœ ë³€ê²½ì‚¬í•­ ì ìš©
        for key, value in suggestion['config_changes'].items():
            if key not in config:
                config[key] = {}
            if isinstance(value, dict):
                config[key].update(value)
            else:
                config[key] = value

        config_name = f"test_config_{i}_{suggestion['name'].replace(' ', '_').lower()}.yaml"
        test_configs.append((suggestion['name'], config, config_name))

    return test_configs


def print_summary(log_data: Dict, suggestions: List[Dict]):
    """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
    print("\n" + "=" * 80)
    print("ğŸ¯ RECOMMENDED IMPROVEMENTS")
    print("=" * 80)

    for i, suggestion in enumerate(suggestions, 1):
        print(f"\n{i}. {suggestion['name']}")
        print(f"   ğŸ“ {suggestion['description']}")
        print(f"   ğŸ’¡ Reason: {suggestion['reason']}")
        print(f"   âš™ï¸  Config Changes: {suggestion['config_changes']}")

    print("\n" + "=" * 80)
    print("ğŸ’» To test these suggestions:")
    print("=" * 80)
    print("\nExample command:")
    print("  python CR_recon/train.py --config test_config_0_xxx.yaml")
    print("\në¹„êµ:")
    print("  1. ì²«ë²ˆì§¸ ì œì•ˆìœ¼ë¡œ í•™ìŠµ ì‹¤í–‰ â†’ outputs/train_log.txt í™•ì¸")
    print("  2. best_val_loss ê°’ ë¹„êµ")
    print("  3. ë” ë‚®ì€ lossë¥¼ ì£¼ëŠ” ì„¤ì • ì±„íƒ")
    print("\n" + "=" * 80)


def main():
    parser = argparse.ArgumentParser(description='Train log ë¶„ì„ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”')
    parser.add_argument('--log', required=True, help='Train log íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--base-config', default='CR_recon/configs/default.yaml',
                      help='Base config íŒŒì¼ ê²½ë¡œ')
    args = parser.parse_args()

    # Log íŒŒì‹±
    print(f"\nğŸ“– Parsing log file: {args.log}")
    log_data = parse_train_log(args.log)

    # ì œì•ˆ ìƒì„±
    suggestions = generate_suggestions(log_data)

    # ìš”ì•½ ì¶œë ¥
    print_summary(log_data, suggestions)

    # í…ŒìŠ¤íŠ¸ config ìƒì„± (ì„ íƒì‚¬í•­)
    if suggestions:
        print("\nâœ… í…ŒìŠ¤íŠ¸ config ìƒì„± ì¤‘...")
        test_configs = create_test_configs(args.base_config, suggestions)
        for name, config, filename in test_configs:
            config_path = Path('CR_recon/configs') / filename
            with open(config_path, 'w') as f:
                yaml.dump(config, f, default_flow_style=False)
            print(f"  - {filename} (for: {name})")


if __name__ == '__main__':
    main()
